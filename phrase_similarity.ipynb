{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# import relevant packages\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cosine\n",
    "from datasets import load_dataset\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Phrase similarity with static embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"PiC/phrase_similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "valid_data = dataset['validation']\n",
    "test_data = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'phrase1': ['newly formed camp',\n",
       "  'one data',\n",
       "  'particular structure',\n",
       "  'involved people',\n",
       "  'different cross'],\n",
       " 'phrase2': ['recently made encampment',\n",
       "  'a particular statistic',\n",
       "  'specific edifice',\n",
       "  'participating individuals',\n",
       "  'opposing inquiries'],\n",
       " 'sentence1': ['newly formed camp is released from the membrane and diffuses across the intracellular space where it serves to activate pka.',\n",
       "  \"According to one data, in 1910, on others – in 1915, the mansion became Natalya Dmitriyevna Shchuchkina's property.\",\n",
       "  'Note that Fact 1 does not assume any particular structure on the set formula_65.',\n",
       "  'Assessment-Center are usually group-processes with high validity and acceptance of the involved people.',\n",
       "  'At the end of the 1980s, a different cross had been placed on the roof.'],\n",
       " 'sentence2': ['recently made encampment is released from the membrane and diffuses across the intracellular space where it serves to activate pka.',\n",
       "  \"According to a particular statistic, in 1910, on others – in 1915, the mansion became Natalya Dmitriyevna Shchuchkina's property.\",\n",
       "  'Note that Fact 1 does not assume any specific edifice on the set formula_65.',\n",
       "  'Assessment-Center are usually group-processes with high validity and acceptance of the participating individuals.',\n",
       "  'At the end of the 1980s, a opposing inquiries had been placed on the roof.'],\n",
       " 'label': [0, 1, 0, 1, 0],\n",
       " 'idx': [0, 1, 2, 3, 4]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7004"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        embeddings = {}\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings[word] = vector\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'glove.6B/glove.6B.300d.txt'\n",
    "glove_embeddings = load_glove_embeddings(path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarity(vec1, vec2):\n",
    "    return 1 - cosine(vec1, vec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are computing the phrase embeddings by calculating the mean of the embeddings of each word to start of with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phrase_embedding(phrase, embeddings_dict):\n",
    "    embeddings = [embeddings_dict[word.lower()] for word in phrase.split() if word.lower() in embeddings_dict]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(next(iter(embeddings_dict.values())).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_and_labels(data, glove_embeddings):\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    for example in data:\n",
    "        phrase1_embedding = get_phrase_embedding(example['phrase1'], glove_embeddings)\n",
    "        phrase2_embedding = get_phrase_embedding(example['phrase2'], glove_embeddings)\n",
    "        embedding = np.concatenate((phrase1_embedding, phrase2_embedding))\n",
    "        embeddings.append(embedding)\n",
    "        labels.append(example['label'])\n",
    "    return np.array(embeddings), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = defaultdict(int)\n",
    "for sentences in (train_data['phrase1'] + train_data['phrase2'] + \\\n",
    "                  test_data['phrase1'] + test_data['phrase2'] + \\\n",
    "                    valid_data['phrase1'] + valid_data['phrase2']):\n",
    "    for word in sentences.split():\n",
    "        word_freq[word.lower()] += 1\n",
    "total_words = sum(word_freq.values())\n",
    "word_prob = {word: freq / total_words for word, freq in word_freq.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phrase_embedding_sif(phrase, embeddings_dict, word_prob, a=1e-3):\n",
    "    embeddings = []\n",
    "    weights = []\n",
    "    for word in phrase.split():\n",
    "        if word.lower() in embeddings_dict and word.lower() in word_prob:\n",
    "            embeddings.append(embeddings_dict[word.lower()])\n",
    "            weight = a / (a + word_prob[word.lower()])\n",
    "            weights.append(weight)\n",
    "    if embeddings:\n",
    "        weighted_embeddings = np.average(embeddings, axis=0, weights=weights)\n",
    "        return weighted_embeddings\n",
    "    else:\n",
    "        return np.zeros(next(iter(embeddings_dict.values())).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_and_labels_sif(data, glove_embeddings):\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    for example in data:\n",
    "        phrase1_embedding = get_phrase_embedding_sif(example['phrase1'], glove_embeddings, word_prob=word_prob)\n",
    "        phrase2_embedding = get_phrase_embedding_sif(example['phrase2'], glove_embeddings, word_prob=word_prob)\n",
    "        embedding = np.concatenate((phrase1_embedding, phrase2_embedding))\n",
    "        embeddings.append(embedding)\n",
    "        labels.append(example['label'])\n",
    "    return np.array(embeddings), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_phrases = train_data['phrase1'] + train_data['phrase2'] + \\\n",
    "                valid_data['phrase1'] + valid_data['phrase2'] + \\\n",
    "                test_data['phrase1'] + test_data['phrase2']\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(all_phrases)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "tfidf_scores = dict(zip(feature_names, vectorizer.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phrase_embedding_tfidf(phrase, embeddings_dict, tfidf_scores):\n",
    "    embeddings = []\n",
    "    weights = []\n",
    "    for word in phrase.split():\n",
    "        if word.lower() in embeddings_dict and word.lower() in tfidf_scores:\n",
    "            embeddings.append(embeddings_dict[word.lower()])\n",
    "            weight = tfidf_scores[word.lower()]\n",
    "            weights.append(weight)\n",
    "    if embeddings:\n",
    "        if not weights:\n",
    "            weights = [1] * len(embeddings)\n",
    "        weighted_embeddings = np.average(embeddings, axis=0, weights=weights)\n",
    "        return weighted_embeddings\n",
    "    else:\n",
    "        return np.zeros(next(iter(embeddings_dict.values())).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_and_labels_tfidf(data, embeddings_dict, a=1e-3):\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "\n",
    "    for phrase1, phrase2, label in zip(data['phrase1'], data['phrase2'], data['label']):\n",
    "        phrase1_embedding = get_phrase_embedding_tfidf(phrase1, embeddings_dict, tfidf_scores)\n",
    "        phrase2_embedding = get_phrase_embedding_tfidf(phrase2, embeddings_dict, tfidf_scores)\n",
    "\n",
    "        embedding = np.concatenate((phrase1_embedding, phrase2_embedding))\n",
    "        embeddings.append(embedding)\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(embeddings), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_metrics(actual, predictions):\n",
    "    accuracy = accuracy_score(actual, predictions)\n",
    "    precision = precision_score(actual, predictions)\n",
    "    recall = recall_score(actual, predictions)\n",
    "    f1 = f1_score(actual, predictions)\n",
    "\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a simple cosine similarity function and figuring out the threshold by optimising for the best threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best threshold is 0.55\n",
      "Training Accuracy: 0.5107\n",
      "Training Precision: 0.5200\n",
      "Training Recall: 0.2784\n",
      "Training F1-score: 0.3627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "best_threshold = None\n",
    "best_metric_f1 = -1\n",
    "best_metric_accuracy = -1\n",
    "best_metric_recall = -1\n",
    "best_metric_precision = -1\n",
    "\n",
    "# Create thresholds from 0 to 2, inclusive, in increments of 0.05\n",
    "thresholds = [i * 0.05 for i in range(1, 41)]\n",
    "for threshold in thresholds:\n",
    "    predictions = []\n",
    "    for p1, p2 in zip(train_data['phrase1'], train_data['phrase2']):\n",
    "        emb1 = get_phrase_embedding_tfidf(p1, glove_embeddings, word_prob)\n",
    "        emb2 = get_phrase_embedding_tfidf(p2, glove_embeddings, word_prob)\n",
    "        similarity = get_cosine_similarity(emb1, emb2)\n",
    "        pred = 1 if similarity > threshold else 0\n",
    "        predictions.append(pred)\n",
    "    accuracy, precision, recall, f1 = get_eval_metrics(train_data['label'], predictions)\n",
    "    if accuracy > best_metric_accuracy:\n",
    "        best_metric_f1 = f1\n",
    "        best_metric_accuracy = accuracy\n",
    "        best_metric_precision = precision\n",
    "        best_metric_recall = recall\n",
    "        best_threshold = threshold\n",
    "print(f\"The best threshold is {best_threshold}\")\n",
    "\n",
    "print(f\"Training Accuracy: {best_metric_accuracy:.4f}\")\n",
    "print(f\"Training Precision: {best_metric_precision:.4f}\")\n",
    "print(f\"Training Recall: {best_metric_recall:.4f}\")\n",
    "print(f\"Training F1-score: {best_metric_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best threshold with training set is coming out to be 0.05. Lets use this to see what sort of a score we would get with the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5105\n",
      "Test Precision: 0.5517\n",
      "Test Recall: 0.1120\n",
      "Test F1-score: 0.1862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/encrypted_soul/.virtualenvs/research--nlp/lib/python3.9/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "threshold = 0.65\n",
    "\n",
    "for p1, p2 in zip(test_data['phrase1'], test_data['phrase2']):\n",
    "    emb1 = get_phrase_embedding_tfidf(p1, glove_embeddings, word_prob)\n",
    "    emb2 = get_phrase_embedding_tfidf(p2, glove_embeddings, word_prob)\n",
    "    similarity = get_cosine_similarity(emb1, emb2)\n",
    "    pred = 1 if similarity > threshold else 0\n",
    "    predictions.append(pred)\n",
    "\n",
    "actual = test_data['label']\n",
    "accuracy, precision, recall, f1 = get_eval_metrics(actual, predictions)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.5651\n",
      "Training Precision: 0.5645\n",
      "Training Recall: 0.5700\n",
      "Training F1-score: 0.5672\n",
      "Validation Accuracy: 0.3710\n",
      "Validation Precision: 0.3733\n",
      "Validation Recall: 0.3800\n",
      "Validation F1-score: 0.3766\n",
      "Test Accuracy: 0.3540\n",
      "Test Precision: 0.3574\n",
      "Test Recall: 0.3660\n",
      "Test F1-score: 0.3617\n"
     ]
    }
   ],
   "source": [
    "train_embeddings, train_labels = get_embeddings_and_labels(train_data, glove_embeddings)\n",
    "model = LogisticRegression(\n",
    "    C=10,\n",
    "    penalty='l1',\n",
    "    solver='liblinear',\n",
    "    max_iter=500,\n",
    "    tol=1e-5,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(train_embeddings, train_labels)\n",
    "\n",
    "train_predictions = model.predict(train_embeddings)\n",
    "accuracy, precision, recall, f1 = get_eval_metrics(train_labels, train_predictions)\n",
    "print(f\"Training Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Training Precision: {precision:.4f}\")\n",
    "print(f\"Training Recall: {recall:.4f}\")\n",
    "print(f\"Training F1-score: {f1:.4f}\")\n",
    "\n",
    "valid_embeddings, valid_labels = get_embeddings_and_labels(valid_data, glove_embeddings)\n",
    "valid_predictions = model.predict(valid_embeddings)\n",
    "accuracy, precision, recall, f1 = get_eval_metrics(valid_labels, valid_predictions)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Validation Precision: {precision:.4f}\")\n",
    "print(f\"Validation Recall: {recall:.4f}\")\n",
    "print(f\"Validation F1-score: {f1:.4f}\")\n",
    "\n",
    "test_embeddings, test_labels = get_embeddings_and_labels(test_data, glove_embeddings)\n",
    "test_predictions = model.predict(test_embeddings)\n",
    "accuracy, precision, recall, f1 = get_eval_metrics(test_labels, test_predictions)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.5667\n",
      "Training Precision: 0.5655\n",
      "Training Recall: 0.5754\n",
      "Training F1-score: 0.5704\n",
      "Validation Accuracy: 0.3500\n",
      "Validation Precision: 0.3541\n",
      "Validation Recall: 0.3640\n",
      "Validation F1-score: 0.3590\n",
      "Test Accuracy: 0.3555\n",
      "Test Precision: 0.3607\n",
      "Test Recall: 0.3740\n",
      "Test F1-score: 0.3672\n"
     ]
    }
   ],
   "source": [
    "train_embeddings, train_labels = get_embeddings_and_labels_sif(train_data, glove_embeddings)\n",
    "model = LogisticRegression(\n",
    "    C=10,\n",
    "    penalty='l1',\n",
    "    solver='liblinear',\n",
    "    max_iter=500,\n",
    "    tol=1e-5,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(train_embeddings, train_labels)\n",
    "\n",
    "train_predictions = model.predict(train_embeddings)\n",
    "accuracy, precision, recall, f1 = get_eval_metrics(train_labels, train_predictions)\n",
    "print(f\"Training Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Training Precision: {precision:.4f}\")\n",
    "print(f\"Training Recall: {recall:.4f}\")\n",
    "print(f\"Training F1-score: {f1:.4f}\")\n",
    "\n",
    "valid_embeddings, valid_labels = get_embeddings_and_labels_sif(valid_data, glove_embeddings)\n",
    "valid_predictions = model.predict(valid_embeddings)\n",
    "accuracy, precision, recall, f1 = get_eval_metrics(valid_labels, valid_predictions)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Validation Precision: {precision:.4f}\")\n",
    "print(f\"Validation Recall: {recall:.4f}\")\n",
    "print(f\"Validation F1-score: {f1:.4f}\")\n",
    "\n",
    "test_embeddings, test_labels = get_embeddings_and_labels_sif(test_data, glove_embeddings)\n",
    "test_predictions = model.predict(test_embeddings)\n",
    "accuracy, precision, recall, f1 = get_eval_metrics(test_labels, test_predictions)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.5657\n",
      "Training Precision: 0.5654\n",
      "Training Recall: 0.5680\n",
      "Training F1-score: 0.5667\n",
      "Validation Accuracy: 0.3760\n",
      "Validation Precision: 0.3789\n",
      "Validation Recall: 0.3880\n",
      "Validation F1-score: 0.3834\n",
      "Test Accuracy: 0.3500\n",
      "Test Precision: 0.3521\n",
      "Test Recall: 0.3570\n",
      "Test F1-score: 0.3545\n"
     ]
    }
   ],
   "source": [
    "train_embeddings, train_labels = get_embeddings_and_labels_tfidf(train_data, glove_embeddings)\n",
    "model = LogisticRegression(\n",
    "    C=10,\n",
    "    penalty='l1',\n",
    "    solver='liblinear',\n",
    "    max_iter=500,\n",
    "    tol=1e-5,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(train_embeddings, train_labels)\n",
    "\n",
    "train_predictions = model.predict(train_embeddings)\n",
    "accuracy, precision, recall, f1 = get_eval_metrics(train_labels, train_predictions)\n",
    "print(f\"Training Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Training Precision: {precision:.4f}\")\n",
    "print(f\"Training Recall: {recall:.4f}\")\n",
    "print(f\"Training F1-score: {f1:.4f}\")\n",
    "\n",
    "valid_embeddings, valid_labels = get_embeddings_and_labels_tfidf(valid_data, glove_embeddings)\n",
    "valid_predictions = model.predict(valid_embeddings)\n",
    "accuracy, precision, recall, f1 = get_eval_metrics(valid_labels, valid_predictions)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Validation Precision: {precision:.4f}\")\n",
    "print(f\"Validation Recall: {recall:.4f}\")\n",
    "print(f\"Validation F1-score: {f1:.4f}\")\n",
    "\n",
    "test_embeddings, test_labels = get_embeddings_and_labels_tfidf(test_data, glove_embeddings)\n",
    "test_predictions = model.predict(test_embeddings)\n",
    "accuracy, precision, recall, f1 = get_eval_metrics(test_labels, test_predictions)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't seem like the score is improving with logistic regression hyper parameters fine tuning. Lets use SVM instead of logistic regression and see if it helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.5293\n",
      "Training Precision: 0.5588\n",
      "Training Recall: 0.2781\n",
      "Training F1-score: 0.3714\n",
      "Validation Accuracy: 0.4460\n",
      "Validation Precision: 0.3929\n",
      "Validation Recall: 0.1980\n",
      "Validation F1-score: 0.2633\n",
      "Test Accuracy: 0.4335\n",
      "Test Precision: 0.3588\n",
      "Test Recall: 0.1690\n",
      "Test F1-score: 0.2298\n"
     ]
    }
   ],
   "source": [
    "train_embeddings = []\n",
    "train_labels = []\n",
    "for example in train_data:\n",
    "    phrase1_embedding = get_phrase_embedding(example['phrase1'], glove_embeddings)\n",
    "    phrase2_embedding = get_phrase_embedding(example['phrase2'], glove_embeddings)\n",
    "    embedding = np.concatenate((phrase1_embedding, phrase2_embedding))\n",
    "    train_embeddings.append(embedding)\n",
    "    train_labels.append(example['label'])\n",
    "\n",
    "model = SVC(\n",
    "    C=1.0,\n",
    "    kernel='sigmoid',\n",
    "    degree=3,\n",
    "    gamma='auto',\n",
    "    coef0=0.0,\n",
    "    shrinking=True,\n",
    "    probability=False,\n",
    "    tol=1e-3,\n",
    "    cache_size=200,\n",
    "    class_weight='balanced',\n",
    "    verbose=False,\n",
    "    max_iter=-1,\n",
    "    decision_function_shape='ovr',\n",
    "    break_ties=False,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(train_embeddings, train_labels)\n",
    "\n",
    "train_predictions = model.predict(train_embeddings)\n",
    "accuracy, precision, recall, f1 = get_eval_metrics(train_labels, train_predictions)\n",
    "print(f\"Training Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Training Precision: {precision:.4f}\")\n",
    "print(f\"Training Recall: {recall:.4f}\")\n",
    "print(f\"Training F1-score: {f1:.4f}\")\n",
    "\n",
    "valid_embeddings, valid_labels = get_embeddings_and_labels(valid_data, glove_embeddings)\n",
    "valid_predictions = model.predict(valid_embeddings)\n",
    "accuracy, precision, recall, f1 = get_eval_metrics(valid_labels, valid_predictions)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Validation Precision: {precision:.4f}\")\n",
    "print(f\"Validation Recall: {recall:.4f}\")\n",
    "print(f\"Validation F1-score: {f1:.4f}\")\n",
    "\n",
    "test_embeddings, test_labels = get_embeddings_and_labels(test_data, glove_embeddings)\n",
    "test_predictions = model.predict(test_embeddings)\n",
    "accuracy, precision, recall, f1 = get_eval_metrics(test_labels, test_predictions)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.6550\n",
      "Training Precision: 0.6264\n",
      "Training Recall: 0.7680\n",
      "Training F1-score: 0.6900\n",
      "Validation Accuracy: 0.6550\n",
      "Validation Precision: 0.6264\n",
      "Validation Recall: 0.7680\n",
      "Validation F1-score: 0.6900\n",
      "Test Accuracy: 0.4925\n",
      "Test Precision: 0.4937\n",
      "Test Recall: 0.5910\n",
      "Test F1-score: 0.5380\n"
     ]
    }
   ],
   "source": [
    "train_embeddings, train_labels = get_embeddings_and_labels_sif(valid_data, glove_embeddings)\n",
    "\n",
    "model = SVC(\n",
    "    C=1.0,\n",
    "    kernel='sigmoid',\n",
    "    degree=3,\n",
    "    gamma='auto',\n",
    "    coef0=0.0,\n",
    "    shrinking=True,\n",
    "    probability=False,\n",
    "    tol=1e-3,\n",
    "    cache_size=200,\n",
    "    class_weight='balanced',\n",
    "    verbose=False,\n",
    "    max_iter=-1,\n",
    "    decision_function_shape='ovr',\n",
    "    break_ties=False,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(train_embeddings, train_labels)\n",
    "\n",
    "train_predictions = model.predict(train_embeddings)\n",
    "accuracy, precision, recall, f1 = get_eval_metrics(train_labels, train_predictions)\n",
    "print(f\"Training Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Training Precision: {precision:.4f}\")\n",
    "print(f\"Training Recall: {recall:.4f}\")\n",
    "print(f\"Training F1-score: {f1:.4f}\")\n",
    "\n",
    "valid_embeddings, valid_labels = get_embeddings_and_labels_sif(valid_data, glove_embeddings)\n",
    "valid_predictions = model.predict(valid_embeddings)\n",
    "accuracy, precision, recall, f1 = get_eval_metrics(valid_labels, valid_predictions)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Validation Precision: {precision:.4f}\")\n",
    "print(f\"Validation Recall: {recall:.4f}\")\n",
    "print(f\"Validation F1-score: {f1:.4f}\")\n",
    "\n",
    "test_embeddings, test_labels = get_embeddings_and_labels_sif(test_data, glove_embeddings)\n",
    "test_predictions = model.predict(test_embeddings)\n",
    "accuracy, precision, recall, f1 = get_eval_metrics(test_labels, test_predictions)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.5290\n",
      "Training Precision: 0.5642\n",
      "Training Recall: 0.2547\n",
      "Training F1-score: 0.3510\n",
      "Validation Accuracy: 0.4460\n",
      "Validation Precision: 0.3795\n",
      "Validation Recall: 0.1700\n",
      "Validation F1-score: 0.2348\n",
      "Test Accuracy: 0.4305\n",
      "Test Precision: 0.3395\n",
      "Test Recall: 0.1470\n",
      "Test F1-score: 0.2052\n"
     ]
    }
   ],
   "source": [
    "train_embeddings = []\n",
    "train_labels = []\n",
    "for example in train_data:\n",
    "    phrase1_embedding = get_phrase_embedding_tfidf(example['phrase1'], glove_embeddings, tfidf_scores)\n",
    "    phrase2_embedding = get_phrase_embedding_tfidf(example['phrase2'], glove_embeddings, tfidf_scores)\n",
    "    embedding = np.concatenate((phrase1_embedding, phrase2_embedding))\n",
    "    train_embeddings.append(embedding)\n",
    "    train_labels.append(example['label'])\n",
    "\n",
    "model = SVC(\n",
    "    C=1.0,\n",
    "    kernel='sigmoid',\n",
    "    degree=3,\n",
    "    gamma='auto',\n",
    "    coef0=0.0,\n",
    "    shrinking=True,\n",
    "    probability=False,\n",
    "    tol=1e-3,\n",
    "    cache_size=200,\n",
    "    class_weight='balanced',\n",
    "    verbose=False,\n",
    "    max_iter=-1,\n",
    "    decision_function_shape='ovr',\n",
    "    break_ties=False,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(train_embeddings, train_labels)\n",
    "\n",
    "train_predictions = model.predict(train_embeddings)\n",
    "accuracy, precision, recall, f1 = get_eval_metrics(train_labels, train_predictions)\n",
    "print(f\"Training Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Training Precision: {precision:.4f}\")\n",
    "print(f\"Training Recall: {recall:.4f}\")\n",
    "print(f\"Training F1-score: {f1:.4f}\")\n",
    "\n",
    "valid_embeddings, valid_labels = get_embeddings_and_labels_tfidf(valid_data, glove_embeddings)\n",
    "valid_predictions = model.predict(valid_embeddings)\n",
    "accuracy, precision, recall, f1 = get_eval_metrics(valid_labels, valid_predictions)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Validation Precision: {precision:.4f}\")\n",
    "print(f\"Validation Recall: {recall:.4f}\")\n",
    "print(f\"Validation F1-score: {f1:.4f}\")\n",
    "\n",
    "test_embeddings, test_labels = get_embeddings_and_labels_tfidf(test_data, glove_embeddings)\n",
    "test_predictions = model.predict(test_embeddings)\n",
    "accuracy, precision, recall, f1 = get_eval_metrics(test_labels, test_predictions)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An SVM classifier did not help either. Lets go for a little more complex model using a simple neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.7126 - roc-auc: 0.4303 - accuracy: 0.4490 - precision: 0.4484 - recall: 0.4429 - f1_score: 0.4456 - val_loss: 0.7077 - val_roc-auc: 0.3607 - val_accuracy: 0.4070 - val_precision: 0.4327 - val_recall: 0.5980 - val_f1_score: 0.5021\n",
      "Epoch 2/10\n",
      "219/219 [==============================] - 0s 860us/step - loss: 0.6962 - roc-auc: 0.4915 - accuracy: 0.4954 - precision: 0.4957 - recall: 0.5260 - f1_score: 0.5104 - val_loss: 0.7198 - val_roc-auc: 0.2824 - val_accuracy: 0.3420 - val_precision: 0.3244 - val_recall: 0.2920 - val_f1_score: 0.3074\n",
      "Epoch 3/10\n",
      "219/219 [==============================] - 0s 865us/step - loss: 0.6908 - roc-auc: 0.5318 - accuracy: 0.5197 - precision: 0.5186 - recall: 0.5488 - f1_score: 0.5333 - val_loss: 0.7366 - val_roc-auc: 0.2275 - val_accuracy: 0.3010 - val_precision: 0.2940 - val_recall: 0.2840 - val_f1_score: 0.2889\n",
      "Epoch 4/10\n",
      "219/219 [==============================] - 0s 836us/step - loss: 0.6874 - roc-auc: 0.5565 - accuracy: 0.5390 - precision: 0.5403 - recall: 0.5228 - f1_score: 0.5314 - val_loss: 0.7517 - val_roc-auc: 0.2078 - val_accuracy: 0.3340 - val_precision: 0.3884 - val_recall: 0.5780 - val_f1_score: 0.4646\n",
      "Epoch 5/10\n",
      "219/219 [==============================] - 0s 827us/step - loss: 0.6833 - roc-auc: 0.5718 - accuracy: 0.5458 - precision: 0.5453 - recall: 0.5517 - f1_score: 0.5485 - val_loss: 0.7767 - val_roc-auc: 0.1909 - val_accuracy: 0.2980 - val_precision: 0.3585 - val_recall: 0.5120 - val_f1_score: 0.4217\n",
      "Epoch 6/10\n",
      "219/219 [==============================] - 0s 813us/step - loss: 0.6792 - roc-auc: 0.5820 - accuracy: 0.5508 - precision: 0.5480 - recall: 0.5808 - f1_score: 0.5639 - val_loss: 0.7856 - val_roc-auc: 0.1655 - val_accuracy: 0.2340 - val_precision: 0.2412 - val_recall: 0.2480 - val_f1_score: 0.2446\n",
      "Epoch 7/10\n",
      "219/219 [==============================] - 0s 812us/step - loss: 0.6733 - roc-auc: 0.6015 - accuracy: 0.5687 - precision: 0.5663 - recall: 0.5862 - f1_score: 0.5761 - val_loss: 0.8347 - val_roc-auc: 0.1552 - val_accuracy: 0.2440 - val_precision: 0.2104 - val_recall: 0.1860 - val_f1_score: 0.1975\n",
      "Epoch 8/10\n",
      "219/219 [==============================] - 0s 816us/step - loss: 0.6683 - roc-auc: 0.6072 - accuracy: 0.5632 - precision: 0.5643 - recall: 0.5551 - f1_score: 0.5597 - val_loss: 0.8504 - val_roc-auc: 0.1366 - val_accuracy: 0.2100 - val_precision: 0.2088 - val_recall: 0.2080 - val_f1_score: 0.2084\n",
      "Epoch 9/10\n",
      "219/219 [==============================] - 0s 803us/step - loss: 0.6607 - roc-auc: 0.6231 - accuracy: 0.5735 - precision: 0.5730 - recall: 0.5774 - f1_score: 0.5752 - val_loss: 0.8896 - val_roc-auc: 0.1247 - val_accuracy: 0.1950 - val_precision: 0.1762 - val_recall: 0.1660 - val_f1_score: 0.1710\n",
      "Epoch 10/10\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.6545 - roc-auc: 0.6359 - accuracy: 0.5847 - precision: 0.5845 - recall: 0.5857 - f1_score: 0.5851 - val_loss: 0.9253 - val_roc-auc: 0.1175 - val_accuracy: 0.1940 - val_precision: 0.1976 - val_recall: 0.2000 - val_f1_score: 0.1988\n",
      "32/32 [==============================] - 0s 707us/step - loss: 0.9253 - roc-auc: 0.1175 - accuracy: 0.1940 - precision: 0.1976 - recall: 0.2000 - f1_score: 0.1988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9253295063972473,\n",
       " 0.11752200126647949,\n",
       " 0.1940000057220459,\n",
       " 0.197628453373909,\n",
       " 0.20000000298023224,\n",
       " array([0.19880715], dtype=float32)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embeddings, train_labels = get_embeddings_and_labels_sif(train_data, glove_embeddings)\n",
    "valid_embeddings, valid_labels = get_embeddings_and_labels_sif(valid_data, glove_embeddings)\n",
    "\n",
    "\n",
    "\n",
    "METRICS = [\n",
    "    tf.keras.metrics.AUC(name='roc-auc'),\n",
    "    tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name=\"recall\"),\n",
    "    tfa.metrics.F1Score(name='f1_score', threshold=0.5, num_classes=1)  # Add F1 score\n",
    "]\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(train_embeddings.shape[1],)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=METRICS)\n",
    "\n",
    "history = model.fit(train_embeddings, train_labels, epochs=10,\n",
    "                    validation_data=(valid_embeddings, valid_labels))\n",
    "\n",
    "model.evaluate(valid_embeddings, valid_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "219/219 [==============================] - 1s 1ms/step - loss: 0.7124 - roc-auc: 0.4439 - accuracy: 0.4580 - precision: 0.4609 - recall: 0.4949 - f1_score: 0.4773 - val_loss: 0.7064 - val_roc-auc: 0.3879 - val_accuracy: 0.4230 - val_precision: 0.4349 - val_recall: 0.5140 - val_f1_score: 0.4711\n",
      "Epoch 2/10\n",
      "219/219 [==============================] - 0s 887us/step - loss: 0.6955 - roc-auc: 0.4935 - accuracy: 0.4913 - precision: 0.4905 - recall: 0.4506 - f1_score: 0.4697 - val_loss: 0.7151 - val_roc-auc: 0.2958 - val_accuracy: 0.3530 - val_precision: 0.3167 - val_recall: 0.2540 - val_f1_score: 0.2819\n",
      "Epoch 3/10\n",
      "219/219 [==============================] - 0s 870us/step - loss: 0.6921 - roc-auc: 0.5278 - accuracy: 0.5208 - precision: 0.5227 - recall: 0.4803 - f1_score: 0.5006 - val_loss: 0.7263 - val_roc-auc: 0.2816 - val_accuracy: 0.3770 - val_precision: 0.4159 - val_recall: 0.6080 - val_f1_score: 0.4939\n",
      "Epoch 4/10\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.6883 - roc-auc: 0.5520 - accuracy: 0.5297 - precision: 0.5301 - recall: 0.5231 - f1_score: 0.5266 - val_loss: 0.7376 - val_roc-auc: 0.2411 - val_accuracy: 0.3040 - val_precision: 0.3172 - val_recall: 0.3400 - val_f1_score: 0.3282\n",
      "Epoch 5/10\n",
      "219/219 [==============================] - 0s 897us/step - loss: 0.6852 - roc-auc: 0.5668 - accuracy: 0.5443 - precision: 0.5474 - recall: 0.5111 - f1_score: 0.5286 - val_loss: 0.7565 - val_roc-auc: 0.2112 - val_accuracy: 0.2830 - val_precision: 0.2972 - val_recall: 0.3180 - val_f1_score: 0.3072\n",
      "Epoch 6/10\n",
      "219/219 [==============================] - 0s 872us/step - loss: 0.6811 - roc-auc: 0.5795 - accuracy: 0.5515 - precision: 0.5518 - recall: 0.5494 - f1_score: 0.5506 - val_loss: 0.7728 - val_roc-auc: 0.1976 - val_accuracy: 0.3060 - val_precision: 0.2006 - val_recall: 0.1300 - val_f1_score: 0.1578\n",
      "Epoch 7/10\n",
      "219/219 [==============================] - 0s 942us/step - loss: 0.6775 - roc-auc: 0.5912 - accuracy: 0.5614 - precision: 0.5641 - recall: 0.5405 - f1_score: 0.5521 - val_loss: 0.7998 - val_roc-auc: 0.1870 - val_accuracy: 0.2720 - val_precision: 0.2220 - val_recall: 0.1820 - val_f1_score: 0.2000\n",
      "Epoch 8/10\n",
      "219/219 [==============================] - 0s 852us/step - loss: 0.6718 - roc-auc: 0.6063 - accuracy: 0.5714 - precision: 0.5726 - recall: 0.5631 - f1_score: 0.5678 - val_loss: 0.8168 - val_roc-auc: 0.1645 - val_accuracy: 0.2330 - val_precision: 0.2292 - val_recall: 0.2260 - val_f1_score: 0.2276\n",
      "Epoch 9/10\n",
      "219/219 [==============================] - 0s 896us/step - loss: 0.6663 - roc-auc: 0.6166 - accuracy: 0.5730 - precision: 0.5748 - recall: 0.5608 - f1_score: 0.5677 - val_loss: 0.8554 - val_roc-auc: 0.1596 - val_accuracy: 0.2310 - val_precision: 0.2457 - val_recall: 0.2600 - val_f1_score: 0.2527\n",
      "Epoch 10/10\n",
      "219/219 [==============================] - 0s 843us/step - loss: 0.6611 - roc-auc: 0.6266 - accuracy: 0.5798 - precision: 0.5827 - recall: 0.5623 - f1_score: 0.5723 - val_loss: 0.8766 - val_roc-auc: 0.1578 - val_accuracy: 0.2420 - val_precision: 0.1692 - val_recall: 0.1320 - val_f1_score: 0.1483\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8766 - roc-auc: 0.1578 - accuracy: 0.2420 - precision: 0.1692 - recall: 0.1320 - f1_score: 0.1483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8765649795532227,\n",
       " 0.1577719897031784,\n",
       " 0.24199999868869781,\n",
       " 0.16923077404499054,\n",
       " 0.13199999928474426,\n",
       " array([0.1483146], dtype=float32)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embeddings, train_labels = get_embeddings_and_labels_tfidf(train_data, glove_embeddings)\n",
    "valid_embeddings, valid_labels = get_embeddings_and_labels_tfidf(valid_data, glove_embeddings)\n",
    "\n",
    "\n",
    "METRICS = [\n",
    "    tf.keras.metrics.AUC(name='roc-auc'),\n",
    "    tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name=\"recall\"),\n",
    "    tfa.metrics.F1Score(name='f1_score', threshold=0.5, num_classes=1)\n",
    "]\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(train_embeddings.shape[1],)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=METRICS)\n",
    "\n",
    "history = model.fit(train_embeddings, train_labels, epochs=10,\n",
    "                    validation_data=(valid_embeddings, valid_labels))\n",
    "\n",
    "model.evaluate(valid_embeddings, valid_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "219/219 [==============================] - 1s 1ms/step - loss: 0.7086 - roc-auc: 0.4369 - accuracy: 0.4469 - precision: 0.4507 - recall: 0.4854 - f1_score: 0.4674 - val_loss: 0.7026 - val_roc-auc: 0.4010 - val_accuracy: 0.4260 - val_precision: 0.4260 - val_recall: 0.4260 - val_f1_score: 0.4260\n",
      "Epoch 2/10\n",
      "219/219 [==============================] - 0s 887us/step - loss: 0.6951 - roc-auc: 0.4987 - accuracy: 0.4984 - precision: 0.4984 - recall: 0.4854 - f1_score: 0.4918 - val_loss: 0.7112 - val_roc-auc: 0.3187 - val_accuracy: 0.3760 - val_precision: 0.3640 - val_recall: 0.3320 - val_f1_score: 0.3473\n",
      "Epoch 3/10\n",
      "219/219 [==============================] - 0s 872us/step - loss: 0.6919 - roc-auc: 0.5312 - accuracy: 0.5274 - precision: 0.5260 - recall: 0.5543 - f1_score: 0.5398 - val_loss: 0.7234 - val_roc-auc: 0.2817 - val_accuracy: 0.3360 - val_precision: 0.3525 - val_recall: 0.3920 - val_f1_score: 0.3712\n",
      "Epoch 4/10\n",
      "219/219 [==============================] - 0s 866us/step - loss: 0.6884 - roc-auc: 0.5510 - accuracy: 0.5306 - precision: 0.5300 - recall: 0.5400 - f1_score: 0.5349 - val_loss: 0.7344 - val_roc-auc: 0.2461 - val_accuracy: 0.3140 - val_precision: 0.3212 - val_recall: 0.3340 - val_f1_score: 0.3275\n",
      "Epoch 5/10\n",
      "219/219 [==============================] - 0s 836us/step - loss: 0.6856 - roc-auc: 0.5648 - accuracy: 0.5484 - precision: 0.5463 - recall: 0.5714 - f1_score: 0.5585 - val_loss: 0.7488 - val_roc-auc: 0.2267 - val_accuracy: 0.3060 - val_precision: 0.2599 - val_recall: 0.2100 - val_f1_score: 0.2323\n",
      "Epoch 6/10\n",
      "219/219 [==============================] - 0s 852us/step - loss: 0.6814 - roc-auc: 0.5780 - accuracy: 0.5490 - precision: 0.5500 - recall: 0.5391 - f1_score: 0.5445 - val_loss: 0.7713 - val_roc-auc: 0.2032 - val_accuracy: 0.3020 - val_precision: 0.3453 - val_recall: 0.4420 - val_f1_score: 0.3877\n",
      "Epoch 7/10\n",
      "219/219 [==============================] - 0s 826us/step - loss: 0.6775 - roc-auc: 0.5896 - accuracy: 0.5603 - precision: 0.5602 - recall: 0.5605 - f1_score: 0.5604 - val_loss: 0.7948 - val_roc-auc: 0.1951 - val_accuracy: 0.2760 - val_precision: 0.2407 - val_recall: 0.2080 - val_f1_score: 0.2232\n",
      "Epoch 8/10\n",
      "219/219 [==============================] - 0s 825us/step - loss: 0.6731 - roc-auc: 0.6004 - accuracy: 0.5664 - precision: 0.5676 - recall: 0.5574 - f1_score: 0.5625 - val_loss: 0.8214 - val_roc-auc: 0.1753 - val_accuracy: 0.2630 - val_precision: 0.2276 - val_recall: 0.1980 - val_f1_score: 0.2118\n",
      "Epoch 9/10\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.6677 - roc-auc: 0.6121 - accuracy: 0.5697 - precision: 0.5695 - recall: 0.5711 - f1_score: 0.5703 - val_loss: 0.8381 - val_roc-auc: 0.1489 - val_accuracy: 0.2290 - val_precision: 0.1969 - val_recall: 0.1760 - val_f1_score: 0.1859\n",
      "Epoch 10/10\n",
      "219/219 [==============================] - 0s 938us/step - loss: 0.6624 - roc-auc: 0.6236 - accuracy: 0.5775 - precision: 0.5797 - recall: 0.5637 - f1_score: 0.5716 - val_loss: 0.8923 - val_roc-auc: 0.1514 - val_accuracy: 0.2360 - val_precision: 0.2643 - val_recall: 0.2960 - val_f1_score: 0.2792\n",
      "32/32 [==============================] - 0s 616us/step - loss: 0.8923 - roc-auc: 0.1514 - accuracy: 0.2360 - precision: 0.2643 - recall: 0.2960 - f1_score: 0.2792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8922796845436096,\n",
       " 0.15143799781799316,\n",
       " 0.23600000143051147,\n",
       " 0.26428571343421936,\n",
       " 0.29600000381469727,\n",
       " array([0.2792453], dtype=float32)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embeddings, train_labels = get_embeddings_and_labels(train_data, glove_embeddings)\n",
    "valid_embeddings, valid_labels = get_embeddings_and_labels(valid_data, glove_embeddings)\n",
    "\n",
    "\n",
    "METRICS = [\n",
    "    tf.keras.metrics.AUC(name='roc-auc'),\n",
    "    tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name=\"recall\"),\n",
    "    tfa.metrics.F1Score(name='f1_score', threshold=0.5, num_classes=1)\n",
    "]\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(train_embeddings.shape[1],)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=METRICS)\n",
    "\n",
    "history = model.fit(train_embeddings, train_labels, epochs=10,\n",
    "                    validation_data=(valid_embeddings, valid_labels))\n",
    "\n",
    "model.evaluate(valid_embeddings, valid_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = TFBertForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "def prepare_input(phrase1, phrase2):\n",
    "    inputs = tokenizer(phrase1, phrase2, return_tensors='tf', padding=True, truncation=True, max_length=128)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_inputs = prepare_input(\"this is awesome\", \"this is terrible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "type(example_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.50\n",
      "Validation accuracy: 0.49\n",
      "Test accuracy: 0.48\n"
     ]
    }
   ],
   "source": [
    "def predict_label(phrase1, phrase2):\n",
    "    inputs = prepare_input(phrase1, phrase2)\n",
    "    outputs = model(inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_label = tf.argmax(logits, axis=1).numpy()[0]\n",
    "    return predicted_label\n",
    "def compute_accuracy(data):\n",
    "    correct_predictions = 0\n",
    "    total_samples = len(data['label'])\n",
    "\n",
    "    for i in range(total_samples):\n",
    "        phrase1 = data['phrase1'][i]\n",
    "        phrase2 = data['phrase2'][i]\n",
    "        true_label = data['label'][i]\n",
    "        predicted_label = predict_label(phrase1, phrase2)\n",
    "        if predicted_label == true_label:\n",
    "            correct_predictions += 1\n",
    "\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    return accuracy\n",
    "train_accuracy = compute_accuracy(train_data)\n",
    "valid_accuracy = compute_accuracy(valid_data)\n",
    "test_accuracy = compute_accuracy(test_data)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy:.2f}\")\n",
    "print(f\"Validation accuracy: {valid_accuracy:.2f}\")\n",
    "print(f\"Test accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2h/3jxpl0dd521c2qvlst0b13jh0000gn/T/ipykernel_83399/755304157.py:4: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  similarity = doc1.similarity(doc2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.50\n",
      "Validation Accuracy: 0.50\n",
      "Test Accuracy: 0.52\n"
     ]
    }
   ],
   "source": [
    "def calculate_similarity(phrase1, phrase2):\n",
    "    doc1 = nlp(phrase1)\n",
    "    doc2 = nlp(phrase2)\n",
    "    similarity = doc1.similarity(doc2)\n",
    "    return similarity\n",
    "\n",
    "def calculate_accuracy(data):\n",
    "    correct_predictions = 0\n",
    "    total_examples = len(data)\n",
    "\n",
    "    for example in data:\n",
    "        phrase1 = example['phrase1']\n",
    "        phrase2 = example['phrase2']\n",
    "        label = example['label']\n",
    "\n",
    "        similarity = calculate_similarity(phrase1, phrase2)\n",
    "        predicted_label = 1 if similarity >= 0.5 else 0\n",
    "\n",
    "        if predicted_label == label:\n",
    "            correct_predictions += 1\n",
    "\n",
    "    accuracy = correct_predictions / total_examples\n",
    "    return accuracy\n",
    "\n",
    "train_accuracy = calculate_accuracy(train_data)\n",
    "valid_accuracy = calculate_accuracy(valid_data)\n",
    "test_accuracy = calculate_accuracy(test_data)\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy:.2f}\")\n",
    "print(f\"Validation Accuracy: {valid_accuracy:.2f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blaze--experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
